# Illustrious AI Studio Configuration
# Model Paths - Update these paths to match your model locations
sd_model: "models/Illustrious.safetensors"  # Path to SDXL .safetensors model file
ollama_model: "goekdenizguelmez/JOSIEFIED-Qwen3:8b-q6_k"  # Ollama model name for text generation
ollama_vision_model: "qwen2.5vl:7b"  # Vision-language model for image analysis and Q&A
ollama_base_url: "http://localhost:11434"  # Ollama API endpoint (default local installation)
gpu_backend: "cuda"  # "cuda", "rocm", or "cpu"
load_models_on_startup: true  # Set false to load models on demand

# Performance settings optimized for RTX 4090M (16GB VRAM)
# Adjust these based on your GPU memory and performance requirements
cuda_settings:
  device: "cuda:0"  # CUDA device to use (cuda:0 for first GPU)
  dtype: "float16"  # Use FP16 precision to save VRAM (vs float32)
  enable_tf32: true  # Enable TensorFloat-32 for faster operations on RTX GPUs
  memory_fraction: 0.95  # Use up to 95% of VRAM (0.8-0.95 recommended, lower if OOM errors)

# Default generation parameters for image creation
# These can be overridden in the UI or API calls
generation_defaults:
  steps: 30  # Number of denoising steps (20-50 typical, higher = quality, lower = speed)
  guidance_scale: 7.5  # How closely to follow the prompt (1-20, 7-8 typical for SDXL)
  width: 1024  # Image width in pixels (1024 is SDXL's native resolution)
  height: 1024  # Image height in pixels (1024 is SDXL's native resolution)
  batch_size: 1  # Number of images to generate simultaneously (keep at 1 to avoid OOM)
